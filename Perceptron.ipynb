{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "X, y = iris.data[:, :2] ,  (iris.target != 0) * 1\n",
    "\n",
    "X, y = X[:100], y[:100]\n",
    "percent = 0.8 #porcentagem da divisao do conjunto de treino e teste\n",
    "n_samples = int(len(X)/2)\n",
    "\n",
    "x1 , x2 , y1 , y2 = [] ,[] ,[] ,[]\n",
    "\n",
    "for i in range(0,n_samples):\n",
    "    x1.append(X[i])\n",
    "    x2.append(X[i + n_samples])\n",
    "    y1.append(y[i])\n",
    "    y2.append(y[i + n_samples])\n",
    "\n",
    "X_train = x1[:int(percent * n_samples)] + x2[:int(percent * n_samples)]\n",
    "y_train = y1[:int(percent * n_samples)] + y2[:int(percent * n_samples)]\n",
    "X_test = x1[int(percent * n_samples):] + x2[int(percent * n_samples):]\n",
    "y_test = y1[int(percent * n_samples):] + y2[int(percent * n_samples):]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerceptronTrainer(BaseEstimator):\n",
    "    \n",
    "    \n",
    "    def __init__(self,analitic = False):\n",
    "            self.analitic = analitic\n",
    "            self._trained = False\n",
    "            self.coef_ = []\n",
    "            self.n_inter = 0\n",
    "            \n",
    "    def fit(self, X, y=None, max_interacao = 1000, alfa = 0.001, tolerancia = 0.1):\n",
    "        \n",
    "        if self.analitic:\n",
    "            \n",
    "            pass\n",
    "        else:\n",
    "        \n",
    "            w = np.zeros(len(X[0]) + 1)\n",
    "            erros = np.zeros(len(X))\n",
    "            \n",
    "            while(self.n_inter < max_interacao):\n",
    "            \n",
    "                i = 0\n",
    "                for xi, yi in zip(X, y):\n",
    "                        aux = 0\n",
    "                        s = np.dot(xi, w[1:]) + w[0]\n",
    "                        if s > 0:\n",
    "                                aux = 1\n",
    "                        else:\n",
    "                                aux = 0            \n",
    "   \n",
    "                        y_pred = aux\n",
    "                        w[2] += alfa* (yi - y_pred) * xi[1]\n",
    "                        w[1] += alfa* (yi - y_pred) * xi[0]\n",
    "                        w[0] += alfa * (yi - y_pred)\n",
    "                        erros[i] = y_pred\n",
    "                        i += 1\n",
    "                    \n",
    "                        #print(\"y_pred = \",y_pred,\"\\t\",\"yi = \",yi)\n",
    "                #print(\"--------------------------------------------------------\")\n",
    "                \n",
    "                \n",
    "                if np.sum(np.equal(erros , y)) == len(y):\n",
    "                    break\n",
    "                \n",
    "                self.n_inter += 1\n",
    "        \n",
    "            pass\n",
    "        self.coef_ = w\n",
    "        self._trained = True\n",
    "        \n",
    "        return self\n",
    "        \n",
    "    def predict(self, X, threshold = 0):\n",
    "        res = []\n",
    "                \n",
    "        if not self._trained:\n",
    "            raise RuntimeError(\"You must train classifer before predicting data!\")\n",
    "    \n",
    "        for xi in X:\n",
    "            s = np.dot(xi, self.coef_[1:]) + self.coef_[0]\n",
    "            \n",
    "            if s > 0:\n",
    "                res.append(1)\n",
    "            else:\n",
    "                res.append(0)   \n",
    "                \n",
    "            \n",
    "        return res\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = PerceptronTrainer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PerceptronTrainer(analitic=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train,y_train,1000,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score( clf.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tPerceptron  Interacoes = 5 \n",
      "--------------------------------------------------------\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "     Iris-Setosa       1.00      0.90      0.95        10\n",
      "Iris-Versicolour       0.91      1.00      0.95        10\n",
      "\n",
      "       micro avg       0.95      0.95      0.95        20\n",
      "       macro avg       0.95      0.95      0.95        20\n",
      "    weighted avg       0.95      0.95      0.95        20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_names = ['Iris-Setosa', 'Iris-Versicolour']\n",
    "\n",
    "print(\"\\tPerceptron \",\"Interacoes =\",clf.n_inter,\"\\n--------------------------------------------------------\\n\",\n",
    "      classification_report(y_test, clf.predict(X_test), target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
